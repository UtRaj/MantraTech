{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**The Objective of the Project is to develop an app where user can enter a pdf and perform following operations in their preferred Language:-**\n",
        "\n",
        "\n",
        "**1. Generate PDF Overview in terms of Course Outline.**\n",
        "\n",
        "**2. Generate Questions from PDF in terms of MCQ, Short Answer Questions and Fill in the Blanks.**\n",
        "\n",
        "**3. Chat with PDF.**"
      ],
      "metadata": {
        "id": "OUw1VtBvdlJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Installing Packages**"
      ],
      "metadata": {
        "id": "SixW37yFd2LU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMHiMCXwrSaR"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers\n",
        "!pip install sentence_transformers\n",
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. VidyaVistaar**"
      ],
      "metadata": {
        "id": "AcCaLEmdfo2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import faiss\n",
        "import time\n",
        "import PyPDF2\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from io import BytesIO\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Configure the Embedding Model and FAISS for Vector-based Retrieval\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "index = faiss.IndexFlatL2(384)\n",
        "metadata = {}\n",
        "\n",
        "\n",
        "# Configure the Google Generative AI API\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "\n",
        "# Extract texts from the pdf\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Splits text into sentence-aware chunks with overlap.\n",
        "def split_text_into_chunks(text, max_chunk_size=2000, overlap=50):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 > max_chunk_size:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = current_chunk[-overlap:] + sentence\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                current_chunk += \". \" + sentence\n",
        "            else:\n",
        "                current_chunk = sentence\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Generates embeddings for text chunks and stores them in FAISS.\n",
        "def generate_and_store_embeddings(text, doc_id=\"doc1\"):\n",
        "  chunks = split_text_into_chunks(text)\n",
        "  embeddings = embedding_model.encode(chunks)\n",
        "  embeddings = np.array(embeddings).astype(np.float32)\n",
        "  index.add(embeddings)  # Add embeddings to FAISS index\n",
        "\n",
        "  # Store metadata for each embedding\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    metadata[len(metadata)] = {\"chunk\": chunk, \"doc_id\": doc_id}\n",
        "\n",
        "\n",
        "# Retrieves the top-k most relevant chunks for a query.\n",
        "def retrieve_chunks(query, top_k=5):\n",
        "    try:\n",
        "        query_embedding = embedding_model.encode([query])\n",
        "        query_embedding = np.array(query_embedding).astype(np.float32)\n",
        "\n",
        "        # Debugging: Check if the query embedding has the correct shape\n",
        "        # print(f\"Query embedding shape: {query_embedding.shape}\")\n",
        "\n",
        "        # Debugging: Print the current number of items in the FAISS index\n",
        "        # print(f\"FAISS index contains {index.ntotal} embeddings.\")\n",
        "\n",
        "        distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "        # Debugging: Print distances and indices\n",
        "        # print(f\"Distances: {distances}\")\n",
        "        # print(f\"Indices: {indices}\")\n",
        "\n",
        "        # Filter out invalid indices (i.e., those equal to -1) and corresponding distances\n",
        "        valid_indices = [i for i, idx in enumerate(indices[0]) if idx != -1]\n",
        "        valid_distances = [distances[0][i] for i in valid_indices]\n",
        "        valid_indices = [indices[0][i] for i in valid_indices]\n",
        "\n",
        "        if len(valid_indices) == 0:\n",
        "            raise ValueError(\"No relevant chunks found for the query.\")\n",
        "\n",
        "        # Fetch the corresponding chunks from metadata\n",
        "        results = [{\"chunk\": metadata[idx][\"chunk\"], \"doc_id\": metadata[idx][\"doc_id\"]} for idx in valid_indices]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during chunk retrieval: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Generate Course with RAG\n",
        "def generate_rescontent(query, retrieved_chunks, prompt):\n",
        "    \"\"\"\n",
        "    This function generates a response using RAG. It retrieves relevant chunks from the document and generates a structured response.\n",
        "    task_type specifies what type of content to generate (e.g., course, MCQ).\n",
        "    \"\"\"\n",
        "    if not retrieved_chunks:\n",
        "        return \"Sorry, I couldn't find any relevant information for your request.\"\n",
        "\n",
        "    # Prepare the context by joining relevant chunks\n",
        "    retrieved_context = \" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks])\n",
        "    full_prompt = f\"{prompt}\\n\\n{retrieved_context}\\n\\nGenerated Content:\"\n",
        "\n",
        "    # Generate content using the generative model\n",
        "    response = model.generate_content(full_prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# Generates a response For Chatbot using Google Gemini.\n",
        "def generate_response(query, retrieved_chunks):\n",
        "    if not retrieved_chunks:\n",
        "      return \"Sorry, I couldn't find any relevant information for your question.\"\n",
        "\n",
        "    retrieved_context = \" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks])\n",
        "    prompt = f\"Context: {retrieved_context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# Translate the response before giving the Output.\n",
        "def translate_text(text, language_name):\n",
        "    prompt = f\"Translate the following text to {language_name}: {text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    if response.parts:\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        raise ValueError(\"No valid parts in response.\")\n",
        "\n",
        "\n",
        "# Various Prompts for Various Tasks.\n",
        "def create_prompts(text, task_type):\n",
        "    prompts = {\n",
        "        \"mcq\": f\"Read the following text carefully and generate multiple-choice questions. Each question should include:\\n\"\n",
        "               f\"1. A clear and concise question based on the text.\\n\"\n",
        "               f\"2. Give a question with Four options (A, B, C, D), with one correct answer clearly indicated.\\n\"\n",
        "               f\"3. The questions should cover key concepts, definitions, critical points, and significant details discussed in the text.\\n\"\n",
        "               f\"4. Ensure the options are plausible and relevant to the content.\\n\\n\"\n",
        "               f\"Text:\\n{text}\\n\\nMCQ:\",\n",
        "        \"fill_in_the_blank\": f\"Read the following text thoroughly and generate fill-in-the-blank questions. Each question should include:\\n\"\n",
        "                            f\"1. A sentence from the text with one key term or concept replaced by a blank.\\n\"\n",
        "                            f\"2. The correct term or concept that completes the sentence accurately.\\n\"\n",
        "                            f\"3. Focus on important information, such as key terms, dates, names, and concepts that are critical to understanding the text.\\n\\n\"\n",
        "                            f\"Text:\\n{text}\\n\\nFill in the blank:\",\n",
        "        \"short_answer\": f\"Read the following text attentively and generate short answer questions. Each question should include:\\n\"\n",
        "                        f\"1. A clear and specific question that requires a brief response.\\n\"\n",
        "                        f\"2. The response should address key points, explanations, or definitions provided in the text.\\n\"\n",
        "                        f\"3. Ensure the questions encourage critical thinking and comprehension of the material, focusing on important details and concepts.\\n\\n\"\n",
        "                        f\"Text:\\n{text}\\n\\nShort answer question:\",\n",
        "        \"course\": f\"Read the following text and generate a comprehensive, structured curriculum content. The content should include:\\n\"\n",
        "                  f\"1. Learning objectives and outcomes.\\n\"\n",
        "                  f\"2. Topic-wise breakdown with detailed descriptions.\\n\"\n",
        "                  f\"3. Key concepts, definitions, and explanations.\\n\"\n",
        "                  f\"4. Examples, illustrations, and case studies.\\n\"\n",
        "                  f\"5. Assessment and evaluation criteria.\\n\\n\"\n",
        "                  f\"Text:\\n{text}\\n\\nCurriculum Content:\",\n",
        "    }\n",
        "    return prompts.get(task_type, \"\")\n",
        "\n",
        "\n",
        "# Get User Input from User.\n",
        "def get_user_input(prompt):\n",
        "    return input(prompt)\n",
        "\n",
        "\n",
        "# Chatbot Functionality.\n",
        "def chatbot():\n",
        "    print(\"Welcome to the AnantaLearn Chatbot!!!!\")\n",
        "    pdf_path = get_user_input(\"Enter the path to your PDF file: \")\n",
        "    try:\n",
        "      pdf_text = extract_text_from_pdf(pdf_path)\n",
        "      generate_and_store_embeddings(pdf_text, doc_id=\"pdf_doc\")\n",
        "      print(f\"PDF loaded and processed successfully. You can now ask questions related to the document.\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading PDF: {e}\")\n",
        "      return\n",
        "\n",
        "    languages = [\n",
        "        \"Arabic\", \"Czech\", \"German\", \"English\", \"Spanish\", \"Estonian\", \"Finnish\", \"French\", \"Gujarati\",\n",
        "        \"Hindi\", \"Italian\", \"Japanese\", \"Kazakh\", \"Korean\", \"Lithuanian\", \"Latvian\", \"Burmese\", \"Nepali\",\n",
        "        \"Dutch\", \"Romanian\", \"Russian\", \"Sinhala\", \"Turkish\", \"Vietnamese\", \"Chinese\", \"Afrikaans\",\n",
        "        \"Azerbaijani\", \"Bengali\", \"Persian\", \"Hebrew\", \"Croatian\", \"Indonesian\", \"Georgian\", \"Khmer\",\n",
        "        \"Macedonian\", \"Malayalam\", \"Mongolian\", \"Marathi\", \"Polish\", \"Pashto\", \"Portuguese\", \"Swedish\",\n",
        "        \"Swahili\", \"Tamil\", \"Telugu\", \"Thai\", \"Tagalog\", \"Ukrainian\", \"Urdu\", \"Xhosa\", \"Galician\",\n",
        "        \"Slovene\"\n",
        "    ]\n",
        "\n",
        "    print(\"Available languages:\")\n",
        "    for language in languages:\n",
        "        print(language)\n",
        "\n",
        "    while True:\n",
        "        language_choice = get_user_input(\"Choose a language for the output: \")\n",
        "        if language_choice in languages:\n",
        "            language_name = language_choice\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please choose a valid language.\")\n",
        "\n",
        "    text_chunks = split_text_into_chunks(pdf_text)\n",
        "\n",
        "    while True:\n",
        "        main_choice = get_user_input(\"Choose an option: (1) Generate Course, (2) Generate Questions, (3) Chat with PDF, (4) Exit: \").lower()\n",
        "        if main_choice not in ['1', '2', '3', '4']:\n",
        "            print(\"Invalid choice. Please choose either '1', '2', '3', or '4'.\")\n",
        "            continue\n",
        "\n",
        "        if main_choice == '1':    # Option 1: Generate Course\n",
        "            print(\"Generating the course using Retrieval-Augmented Generation (RAG)...\")\n",
        "            prompt = create_prompts(pdf_text, \"course\")\n",
        "            retrieved_chunks = retrieve_chunks(\"Generate a comprehensive course outline based on the following content.\", top_k=5)\n",
        "            course_content = generate_rescontent(\"Generate a course based on the content.\", retrieved_chunks, prompt)\n",
        "            translated_course_content = translate_text(course_content, language_name)\n",
        "            print(\"Generated Course Content:\")\n",
        "            print(translated_course_content)\n",
        "\n",
        "        elif main_choice == '2':   # Option 2: Generate Questions\n",
        "            previous_question_type = None\n",
        "            while True:\n",
        "                question_type = get_user_input(\"Choose the type of questions to generate (mcq, fill_in_the_blank, short_answer): \").lower()\n",
        "                if question_type not in ['mcq', 'fill_in_the_blank', 'short_answer']:\n",
        "                    print(\"Invalid choice. Please choose either 'mcq', 'fill_in_the_blank', or 'short_answer'.\")\n",
        "                    continue\n",
        "                if question_type == previous_question_type:\n",
        "                    print(f\"You've already generated {question_type} questions. Please choose a different type.\")\n",
        "                    continue\n",
        "\n",
        "                num_questions = int(get_user_input(\"Enter the number of questions to generate (5, 10, 15): \"))\n",
        "                if num_questions not in [5, 10, 15]:\n",
        "                    print(\"Invalid number of questions. Please choose either 5, 10, or 15.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Generating {question_type.upper()} questions using Retrieval-Augmented Generation (RAG)...\")\n",
        "                questions = []\n",
        "                # retrieved_chunks = retrieve_chunks(f\"Generate {num_questions} {question_type} questions based on the content.\", top_k=5)\n",
        "                retrieved_chunks = retrieve_chunks(f\"Generate {question_type} questions based on the content.\", top_k=5)\n",
        "                prompt = create_prompts(\" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks]), question_type)\n",
        "\n",
        "\n",
        "                for i in range(num_questions):\n",
        "                  question = generate_rescontent(f\"Generate a {question_type} question based on the context.\", retrieved_chunks, prompt)\n",
        "                  translated_question = translate_text(question, language_name)\n",
        "                  questions.append(translated_question)\n",
        "\n",
        "                print(f\"Questions in questions array :- {len(questions)}\")\n",
        "                print(f\"\\n{question_type.upper()} Questions:\")\n",
        "                for idx, question in enumerate(questions, 1):\n",
        "                  print(f\"{idx}. {question}\")\n",
        "                  print()\n",
        "\n",
        "                another_round = get_user_input(\"Do you want to generate a different type of questions? (yes/no): \").lower()\n",
        "                if another_round != 'yes':\n",
        "                    break\n",
        "                previous_question_type = question_type\n",
        "\n",
        "        elif main_choice == '3':  # Option 3: Chat with PDF\n",
        "            while True:\n",
        "                user_query = get_user_input(\"Ask a question about the content of the PDF: \")\n",
        "                retrieved_chunks = retrieve_chunks(user_query, top_k=5)\n",
        "                response = generate_response(user_query, retrieved_chunks)\n",
        "                translated_answer = translate_text(response, language_name)\n",
        "                print(f\"Answer: {translated_answer}\")\n",
        "\n",
        "                another_question = get_user_input(\"Do you want to ask another question? (yes/no): \").lower()\n",
        "                if another_question != 'yes':\n",
        "                    break\n",
        "\n",
        "        # This exits the main loop.\n",
        "        elif main_choice == '4':\n",
        "            print(\"Exiting the program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# Start the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "Rwj-L0oqrYAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d15c648d-a8c1-4da6-8bc9-7c70de950f20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AnantaLearn Chatbot!!!!\n",
            "Enter the path to your PDF file: /content/DevOps Syllabus.pdf\n",
            "PDF loaded and processed successfully. You can now ask questions related to the document.\n",
            "Available languages:\n",
            "Arabic\n",
            "Czech\n",
            "German\n",
            "English\n",
            "Spanish\n",
            "Estonian\n",
            "Finnish\n",
            "French\n",
            "Gujarati\n",
            "Hindi\n",
            "Italian\n",
            "Japanese\n",
            "Kazakh\n",
            "Korean\n",
            "Lithuanian\n",
            "Latvian\n",
            "Burmese\n",
            "Nepali\n",
            "Dutch\n",
            "Romanian\n",
            "Russian\n",
            "Sinhala\n",
            "Turkish\n",
            "Vietnamese\n",
            "Chinese\n",
            "Afrikaans\n",
            "Azerbaijani\n",
            "Bengali\n",
            "Persian\n",
            "Hebrew\n",
            "Croatian\n",
            "Indonesian\n",
            "Georgian\n",
            "Khmer\n",
            "Macedonian\n",
            "Malayalam\n",
            "Mongolian\n",
            "Marathi\n",
            "Polish\n",
            "Pashto\n",
            "Portuguese\n",
            "Swedish\n",
            "Swahili\n",
            "Tamil\n",
            "Telugu\n",
            "Thai\n",
            "Tagalog\n",
            "Ukrainian\n",
            "Urdu\n",
            "Xhosa\n",
            "Galician\n",
            "Slovene\n",
            "Choose a language for the output: Korean\n",
            "Choose an option: (1) Generate Course, (2) Generate Questions, (3) Chat with PDF, (4) Exit: 1\n",
            "Generating the course using Retrieval-Augmented Generation (RAG)...\n",
            "Generated Course Content:\n",
            "## DevOps 커리큘럼 내용\n",
            "\n",
            "**학습 목표 및 결과:**\n",
            "\n",
            "**목표:**\n",
            "\n",
            "* DevOps 방법론과 SDLC에서의 적용 이해.\n",
            "* Docker 컨테이너화와 그 중요성 탐구.\n",
            "\n",
            "**결과:**\n",
            "\n",
            "* **CO1:** DevOps 개념과 업무 실행 이해.\n",
            "* **CO2:** Git, GitHub, Docker, 컨테이너화 기술을 이용한 실험 수행.\n",
            "* **CO3:** SonarQube 통합을 사용한 Jenkins CI/CD 파이프라인 구축.\n",
            "\n",
            "## 주제별 분석 및 자세한 설명:\n",
            "\n",
            "**모듈 1: DevOps 소개 (4시간)**\n",
            "\n",
            "* DevOps의 정의 및 이점\n",
            "* DevOps의 기둥: 협업, 의사소통, 자동화, 지속적 개선\n",
            "\n",
            "**모듈 2: Git 및 GitHub를 이용한 버전 관리 (4시간)**\n",
            "\n",
            "* Git 설치 및 구성\n",
            "* GitHub 계정 생성 및 관리\n",
            "* Git 저장소 초기화, 커밋 생성, 브랜치 관리\n",
            "* 푸시 요청, 포크, 병합을 통한 협업\n",
            "\n",
            "**모듈 3: GitHub에서 CI/CD 파이프라인 구성 (3시간)**\n",
            "\n",
            "* 워크플로우 구성을 정의하는 YAML 파일 생성\n",
            "* GitHub 액션을 사용한 자동화 빌드, 테스트 및 배포 설정\n",
            "\n",
            "**모듈 4: Docker 컨테이너화 (4시간)**\n",
            "\n",
            "* Docker 설치 및 구성\n",
            "* Docker 이미지 관리 및 컨테이너 상호 작용\n",
            "* 맞춤형 이미지 구축을 위한 Dockerfile 지침 작성\n",
            "\n",
            "**핵심 개념, 정의 및 설명:**\n",
            "\n",
            "* **DevOps:** 개발과 운영 절차를 통합하여 소프트웨어 납기를 가속화하는 접근 방식.\n",
            "* **버전 관리:** 시간이 지남에 따라 코드 변경 사항을 추적하는 시스템.\n",
            "* **Git:** 분산 버전 관리 시스템.\n",
            "* **Docker:** 컨테이너화된 애플리케이션을 생성하고 배포하기 위한 플랫폼.\n",
            "* **컨테이너화:** 애플리케이션을 기반 인프라에서 분리.\n",
            "* **CI/CD:** 빌드, 테스트, 배포를 자동화하기 위한 지속적 통합(CI)과 지속적 배포(CD) 관행.\n",
            "\n",
            "**예제, 그림 및 사례 연구:**\n",
            "\n",
            "* **사례 연구:** 대규모 소프트웨어 개발 프로젝트에서 DevOps 구현.\n",
            "* **예제:** Docker를 사용하여 웹 애플리케이션을 컨테이너화하고 이식성 향상.\n",
            "* **데모:** Jenkins CI/CD 파이프라인 설정을 통해 소프트웨어 빌드와 배포를 자동화.\n",
            "\n",
            "**평가 및 점수 기준:**\n",
            "\n",
            "* **지속적인 강의:**\n",
            "    * 실습 및 토론 참여\n",
            "    * 과제 및 프로젝트 보고서 제출\n",
            "* **시험:**\n",
            "    * 중간 및 기말 시험을 통한 개념 및 기술적 기술 이해도 평가\n",
            "Choose an option: (1) Generate Course, (2) Generate Questions, (3) Chat with PDF, (4) Exit: 4\n",
            "Exiting the program. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}