{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMHiMCXwrSaR"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai\n",
        "!pip install transformers\n",
        "!pip install tika\n",
        "!pip install reportlab\n",
        "!pip install chromadb\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence_transformers\n",
        "!pip install markdown\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import faiss\n",
        "import time\n",
        "import markdown\n",
        "import requests\n",
        "import multiprocessing\n",
        "from io import BytesIO\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Configure the Embedding Model and FAISS for Vector-based Retrieval\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "index = faiss.IndexFlatL2(384)\n",
        "metadata = {}\n",
        "\n",
        "\n",
        "# Configure the Google Generative AI API\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "\n",
        "# Extract texts from the pdf\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Splits text into sentence-aware chunks with overlap.\n",
        "def split_text_into_chunks(text, max_chunk_size=2000, overlap=50):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) + 1 > max_chunk_size:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = current_chunk[-overlap:] + sentence\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                current_chunk += \". \" + sentence\n",
        "            else:\n",
        "                current_chunk = sentence\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Generates embeddings for text chunks and stores them in FAISS.\n",
        "def generate_and_store_embeddings(text, doc_id=\"doc1\"):\n",
        "  chunks = split_text_into_chunks(text)\n",
        "  embeddings = embedding_model.encode(chunks)\n",
        "  embeddings = np.array(embeddings).astype(np.float32)\n",
        "  index.add(embeddings)  # Add embeddings to FAISS index\n",
        "\n",
        "  # Store metadata for each embedding\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    metadata[len(metadata)] = {\"chunk\": chunk, \"doc_id\": doc_id}\n",
        "\n",
        "\n",
        "# Retrieves the top-k most relevant chunks for a query.\n",
        "def retrieve_chunks(query, top_k=5):\n",
        "    try:\n",
        "        query_embedding = embedding_model.encode([query])\n",
        "        query_embedding = np.array(query_embedding).astype(np.float32)\n",
        "\n",
        "        # Debugging: Check if the query embedding has the correct shape\n",
        "        # print(f\"Query embedding shape: {query_embedding.shape}\")\n",
        "\n",
        "        # Debugging: Print the current number of items in the FAISS index\n",
        "        # print(f\"FAISS index contains {index.ntotal} embeddings.\")\n",
        "\n",
        "        distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "        # Debugging: Print distances and indices\n",
        "        # print(f\"Distances: {distances}\")\n",
        "        # print(f\"Indices: {indices}\")\n",
        "\n",
        "        # Filter out invalid indices (i.e., those equal to -1) and corresponding distances\n",
        "        valid_indices = [i for i, idx in enumerate(indices[0]) if idx != -1]\n",
        "        valid_distances = [distances[0][i] for i in valid_indices]\n",
        "        valid_indices = [indices[0][i] for i in valid_indices]\n",
        "\n",
        "        if len(valid_indices) == 0:\n",
        "            raise ValueError(\"No relevant chunks found for the query.\")\n",
        "\n",
        "        # Fetch the corresponding chunks from metadata\n",
        "        results = [{\"chunk\": metadata[idx][\"chunk\"], \"doc_id\": metadata[idx][\"doc_id\"]} for idx in valid_indices]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during chunk retrieval: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Generate Course with RAG\n",
        "def generate_rescontent(query, retrieved_chunks, prompt):\n",
        "    \"\"\"\n",
        "    This function generates a response using RAG. It retrieves relevant chunks from the document and generates a structured response.\n",
        "    task_type specifies what type of content to generate (e.g., course, MCQ).\n",
        "    \"\"\"\n",
        "    if not retrieved_chunks:\n",
        "        return \"Sorry, I couldn't find any relevant information for your request.\"\n",
        "\n",
        "    # Prepare the context by joining relevant chunks\n",
        "    retrieved_context = \" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks])\n",
        "    full_prompt = f\"{prompt}\\n\\n{retrieved_context}\\n\\nGenerated Content:\"\n",
        "\n",
        "    # Generate content using the generative model\n",
        "    response = model.generate_content(full_prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# Generates a response For Chatbot using Google Gemini.\n",
        "def generate_response(query, retrieved_chunks):\n",
        "    if not retrieved_chunks:\n",
        "      return \"Sorry, I couldn't find any relevant information for your question.\"\n",
        "\n",
        "    retrieved_context = \" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks])\n",
        "    prompt = f\"Context: {retrieved_context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "\n",
        "# Translate the response before giving the Output.\n",
        "def translate_text(text, language_name):\n",
        "    prompt = f\"Translate the following text to {language_name}: {text}\"\n",
        "    response = model.generate_content(prompt)\n",
        "    if response.parts:\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        raise ValueError(\"No valid parts in response.\")\n",
        "\n",
        "\n",
        "# Various Prompts for Various Tasks.\n",
        "def create_prompts(text, task_type):\n",
        "    prompts = {\n",
        "        \"mcq\": f\"Read the following text carefully and generate multiple-choice questions. Each question should include:\\n\"\n",
        "               f\"1. A clear and concise question based on the text.\\n\"\n",
        "               f\"2. Give a question with Four options (A, B, C, D), with one correct answer clearly indicated.\\n\"\n",
        "               f\"3. The questions should cover key concepts, definitions, critical points, and significant details discussed in the text.\\n\"\n",
        "               f\"4. Ensure the options are plausible and relevant to the content.\\n\\n\"\n",
        "               f\"Text:\\n{text}\\n\\nMCQ:\",\n",
        "        \"fill_in_the_blank\": f\"Read the following text thoroughly and generate fill-in-the-blank questions. Each question should include:\\n\"\n",
        "                            f\"1. A sentence from the text with one key term or concept replaced by a blank.\\n\"\n",
        "                            f\"2. The correct term or concept that completes the sentence accurately.\\n\"\n",
        "                            f\"3. Focus on important information, such as key terms, dates, names, and concepts that are critical to understanding the text.\\n\\n\"\n",
        "                            f\"Text:\\n{text}\\n\\nFill in the blank:\",\n",
        "        \"short_answer\": f\"Read the following text attentively and generate short answer questions. Each question should include:\\n\"\n",
        "                        f\"1. A clear and specific question that requires a brief response.\\n\"\n",
        "                        f\"2. The response should address key points, explanations, or definitions provided in the text.\\n\"\n",
        "                        f\"3. Ensure the questions encourage critical thinking and comprehension of the material, focusing on important details and concepts.\\n\\n\"\n",
        "                        f\"Text:\\n{text}\\n\\nShort answer question:\",\n",
        "        \"course\": f\"Read the following text and generate a comprehensive, structured curriculum content. The content should include:\\n\"\n",
        "                  f\"1. Learning objectives and outcomes.\\n\"\n",
        "                  f\"2. Topic-wise breakdown with detailed descriptions.\\n\"\n",
        "                  f\"3. Key concepts, definitions, and explanations.\\n\"\n",
        "                  f\"4. Examples, illustrations, and case studies.\\n\"\n",
        "                  f\"5. Assessment and evaluation criteria.\\n\\n\"\n",
        "                  f\"Text:\\n{text}\\n\\nCurriculum Content:\",\n",
        "    }\n",
        "    return prompts.get(task_type, \"\")\n",
        "\n",
        "\n",
        "# Get User Input from User.\n",
        "def get_user_input(prompt):\n",
        "    return input(prompt)\n",
        "\n",
        "\n",
        "# Chatbot Functionality.\n",
        "def chatbot():\n",
        "    print(\"Welcome to the AnantaLearn Chatbot!!!!\")\n",
        "    pdf_path = get_user_input(\"Enter the path to your PDF file: \")\n",
        "    try:\n",
        "      pdf_text = extract_text_from_pdf(pdf_path)\n",
        "      generate_and_store_embeddings(pdf_text, doc_id=\"pdf_doc\")\n",
        "      print(f\"PDF loaded and processed successfully. You can now ask questions related to the document.\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading PDF: {e}\")\n",
        "      return\n",
        "\n",
        "    languages = [\n",
        "        \"Arabic\", \"Czech\", \"German\", \"English\", \"Spanish\", \"Estonian\", \"Finnish\", \"French\", \"Gujarati\",\n",
        "        \"Hindi\", \"Italian\", \"Japanese\", \"Kazakh\", \"Korean\", \"Lithuanian\", \"Latvian\", \"Burmese\", \"Nepali\",\n",
        "        \"Dutch\", \"Romanian\", \"Russian\", \"Sinhala\", \"Turkish\", \"Vietnamese\", \"Chinese\", \"Afrikaans\",\n",
        "        \"Azerbaijani\", \"Bengali\", \"Persian\", \"Hebrew\", \"Croatian\", \"Indonesian\", \"Georgian\", \"Khmer\",\n",
        "        \"Macedonian\", \"Malayalam\", \"Mongolian\", \"Marathi\", \"Polish\", \"Pashto\", \"Portuguese\", \"Swedish\",\n",
        "        \"Swahili\", \"Tamil\", \"Telugu\", \"Thai\", \"Tagalog\", \"Ukrainian\", \"Urdu\", \"Xhosa\", \"Galician\",\n",
        "        \"Slovene\"\n",
        "    ]\n",
        "\n",
        "    print(\"Available languages:\")\n",
        "    for language in languages:\n",
        "        print(language)\n",
        "\n",
        "    while True:\n",
        "        language_choice = get_user_input(\"Choose a language for the output: \")\n",
        "        if language_choice in languages:\n",
        "            language_name = language_choice\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please choose a valid language.\")\n",
        "\n",
        "    text_chunks = split_text_into_chunks(pdf_text)\n",
        "\n",
        "    while True:\n",
        "        main_choice = get_user_input(\"Choose an option: (1) Generate Course, (2) Generate Questions, (3) Chat with PDF, (4) Exit: \").lower()\n",
        "        if main_choice not in ['1', '2', '3', '4']:\n",
        "            print(\"Invalid choice. Please choose either '1', '2', '3', or '4'.\")\n",
        "            continue\n",
        "\n",
        "        if main_choice == '1':    # Option 1: Generate Course\n",
        "            print(\"Generating the course using Retrieval-Augmented Generation (RAG)...\")\n",
        "            prompt = create_prompts(pdf_text, \"course\")\n",
        "            retrieved_chunks = retrieve_chunks(\"Generate a comprehensive course outline based on the following content.\", top_k=5)\n",
        "            course_content = generate_rescontent(\"Generate a course based on the content.\", retrieved_chunks, prompt)\n",
        "            translated_course_content = translate_text(course_content, language_name)\n",
        "            print(\"Generated Course Content:\")\n",
        "            print(translated_course_content)\n",
        "\n",
        "        elif main_choice == '2':   # Option 2: Generate Questions\n",
        "            previous_question_type = None\n",
        "            while True:\n",
        "                question_type = get_user_input(\"Choose the type of questions to generate (mcq, fill_in_the_blank, short_answer): \").lower()\n",
        "                if question_type not in ['mcq', 'fill_in_the_blank', 'short_answer']:\n",
        "                    print(\"Invalid choice. Please choose either 'mcq', 'fill_in_the_blank', or 'short_answer'.\")\n",
        "                    continue\n",
        "                if question_type == previous_question_type:\n",
        "                    print(f\"You've already generated {question_type} questions. Please choose a different type.\")\n",
        "                    continue\n",
        "\n",
        "                num_questions = int(get_user_input(\"Enter the number of questions to generate (5, 10, 15): \"))\n",
        "                if num_questions not in [5, 10, 15]:\n",
        "                    print(\"Invalid number of questions. Please choose either 5, 10, or 15.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Generating {question_type.upper()} questions using Retrieval-Augmented Generation (RAG)...\")\n",
        "                questions = []\n",
        "                # retrieved_chunks = retrieve_chunks(f\"Generate {num_questions} {question_type} questions based on the content.\", top_k=5)\n",
        "                retrieved_chunks = retrieve_chunks(f\"Generate {question_type} questions based on the content.\", top_k=5)\n",
        "                prompt = create_prompts(\" \".join([chunk[\"chunk\"] for chunk in retrieved_chunks]), question_type)\n",
        "\n",
        "\n",
        "                for i in range(num_questions):\n",
        "                  question = generate_rescontent(f\"Generate a {question_type} question based on the context.\", retrieved_chunks, prompt)\n",
        "                  translated_question = translate_text(question, language_name)\n",
        "                  questions.append(translated_question)\n",
        "\n",
        "                print(f\"Questions in questions array :- {len(questions)}\")\n",
        "                print(f\"\\n{question_type.upper()} Questions:\")\n",
        "                for idx, question in enumerate(questions, 1):\n",
        "                  print(f\"{idx}. {question}\")\n",
        "                  print()\n",
        "\n",
        "                another_round = get_user_input(\"Do you want to generate a different type of questions? (yes/no): \").lower()\n",
        "                if another_round != 'yes':\n",
        "                    break\n",
        "                previous_question_type = question_type\n",
        "\n",
        "        elif main_choice == '3':  # Option 3: Chat with PDF\n",
        "            while True:\n",
        "                user_query = get_user_input(\"Ask a question about the content of the PDF: \")\n",
        "                retrieved_chunks = retrieve_chunks(user_query, top_k=5)\n",
        "                response = generate_response(user_query, retrieved_chunks)\n",
        "                translated_answer = translate_text(response, language_name)\n",
        "                print(f\"Answer: {translated_answer}\")\n",
        "\n",
        "                another_question = get_user_input(\"Do you want to ask another question? (yes/no): \").lower()\n",
        "                if another_question != 'yes':\n",
        "                    break\n",
        "\n",
        "        # This exits the main loop.\n",
        "        elif main_choice == '4':\n",
        "            print(\"Exiting the program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# Start the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()\n"
      ],
      "metadata": {
        "id": "Rwj-L0oqrYAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}